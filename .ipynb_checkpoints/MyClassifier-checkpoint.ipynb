{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# print the label species(setosa, versicolor,virginica)\n",
    "print(iris.target_names)\n",
    "\n",
    "# print the names of the four features\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n",
      "[0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3\n",
      " 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.2 0.2\n",
      " 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3\n",
      " 1.5 1.3 1.6 1.  1.3 1.4 1.  1.5 1.  1.4 1.3 1.4 1.5 1.  1.5 1.1 1.8 1.3\n",
      " 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.  1.1 1.  1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3\n",
      " 1.2 1.4 1.2 1.  1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8\n",
      " 1.8 2.5 2.  1.9 2.1 2.  2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.  2.  1.8 2.1 1.8\n",
      " 1.8 1.8 2.1 1.6 1.9 2.  2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3\n",
      " 2.5 2.3 1.9 2.  2.3 1.8]\n"
     ]
    }
   ],
   "source": [
    "# print the iris data (top 5 records)\n",
    "print(len(iris.data))\n",
    "\n",
    "# print the iris labels (0:setosa, 1:versicolor, 2:virginica)\n",
    "print(len(iris.target))\n",
    "\n",
    "print(iris.data[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame of given iris dataset.\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({\n",
    "    'sepal length':iris.data[:,0],\n",
    "    'sepal width':iris.data[:,1],\n",
    "    'petal length':iris.data[:,2],\n",
    "    'petal width':iris.data[:,3],\n",
    "    'species':iris.target\n",
    "})\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
    "y=data['species']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[3.55, 90, 400, 26543]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[5.9 ,3.0, \t5.1, \t1.8, \t]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[7.2, 3. , 5.8, 1.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "corr",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'corr'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-19cc97660138>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'coolwarm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: corr"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (12, 6))\n",
    "sns.heatmap(iris.corr(), cmap = 'coolwarm', annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "df.head(5)\n",
    "```\n",
    "\n",
    "output:\n",
    "\n",
    "```\n",
    "TimeStamp \tX \tY \tZ \tMagnitude \tCoordinateID\n",
    "0 \t2020-07-22 05:10:50:003 \t-17.34 \t29.519999 \t-20.52 \t27.942548 \t0\n",
    "1 \t2020-07-22 05:10:50:022 \t-17.40 \t29.279999 \t-20.22 \t27.751907 \t0\n",
    "2 \t2020-07-22 05:10:50:042 \t-17.22 \t29.699999 \t-20.16 \t27.610759 \t0\n",
    "3 \t2020-07-22 05:10:50:062 \t-17.22 \t29.279999 \t-20.46 \t27.815462 \t0\n",
    "4 \t2020-07-22 05:10:50:082 \t-17.58 \t29.279999 \t-20.64 \t28.171368 \t0\n",
    "```\n",
    "\n",
    "```\n",
    "# Select Features\n",
    "train_df = df.iloc[:,1:]\n",
    "train_df\n",
    "```\n",
    "\n",
    "output:\n",
    "\n",
    "```\n",
    "X \tY \tZ \tMagnitude \tCoordinateID\n",
    "0 \t-17.34 \t29.519999 \t-20.520000 \t27.942548 \t0\n",
    "1 \t-17.40 \t29.279999 \t-20.220000 \t27.751907 \t0\n",
    "2 \t-17.22 \t29.699999 \t-20.160000 \t27.610759 \t0\n",
    "3 \t-17.22 \t29.279999 \t-20.460000 \t27.815462 \t0\n",
    "4 \t-17.58 \t29.279999 \t-20.640000 \t28.171368 \t0\n",
    "... \t... \t... \t... \t... \t...\n",
    "33933 \t-19.32 \t30.300000 \t-20.340000 \t29.113193 \t22\n",
    "33934 \t-18.96 \t30.000000 \t-20.939999 \t29.291041 \t22\n",
    "```\n",
    "\n",
    "```\n",
    "train_AP_strengths = train_df.iloc[:,:3]\n",
    "train_AP_strengths\n",
    "```\n",
    "\n",
    "output:\n",
    "```\n",
    " \tX \tY \tZ\n",
    "0 \t-17.34 \t29.519999 \t-20.520000\n",
    "1 \t-17.40 \t29.279999 \t-20.220000\n",
    "2 \t-17.22 \t29.699999 \t-20.160000\n",
    "3 \t-17.22 \t29.279999 \t-20.460000\n",
    "4 \t-17.58 \t29.279999 \t-20.640000\n",
    "```\n",
    "\n",
    "```\n",
    "#Scale transforms data to center to the mean and component wise scale to unit variance\n",
    "train_AP_features = scale(np.asarray(train_AP_strengths))\n",
    "\n",
    "#Convert coordinates to  a string\n",
    "coordinates = train_df['CoordinateID'].map(str)\n",
    "train_labels = np.asarray(coordinates)\n",
    "\n",
    "train_labels.shape\n",
    "\n",
    "#convert labels to categorical variables, dummy_labels has type 'pandas.core.frame.DataFrame'\n",
    "dummy_labels = pd.get_dummies(train_labels)\n",
    "dummy_labels\n",
    "```\n",
    "\n",
    "output:\n",
    "\n",
    "```\n",
    "\n",
    " \t0 \t1 \t10 \t11 \t12 \t2 \t20 \t21 \t22\n",
    "0 \t1 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t0\n",
    "1 \t1 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t0\n",
    "2 \t1 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t0\n",
    "3 \t1 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t0\n",
    "4 \t1 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t0\n",
    "... \t... \t... \t... \t... \t... \t... \t... \t... \t...\n",
    "33933 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t1\n",
    "```\n",
    "\n",
    "```\n",
    "train_labels = np.asarray(dummy_labels) #labels is an array of shape 19937 x 13.\n",
    "train_labels\n",
    "\n",
    "#generate len(train_AP_features) of floats in between 0 and 1\n",
    "train_val_split = np.random.rand(len(train_AP_features))\n",
    "#convert train_val_split to an array of booleans: if elem < 0.7 = true, else: false\n",
    "train_val_split = train_val_split < 0.70 #should contain ~70% percent true\n",
    "\n",
    "train_X = train_AP_features[train_val_split]\n",
    "train_y = train_labels[train_val_split]\n",
    "val_X = train_AP_features[~train_val_split]\n",
    "val_y = train_labels[~train_val_split]\n",
    "\n",
    "train_X.shape\n",
    "\n",
    "nb_epochs = 30\n",
    "batch_size = 10\n",
    "input_size = 3 \n",
    "num_classes = 9 #Total nine coordinates\n",
    "\n",
    "def encoder():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=input_size, activation='tanh', bias=True))\n",
    "    model.add(Dense(128, activation='tanh', bias=True))\n",
    "    model.add(Dense(64, activation='tanh', bias=True))\n",
    "    return model\n",
    "\n",
    "def decoder(e):   \n",
    "    e.add(Dense(128, input_dim=64, activation='tanh', bias=True))\n",
    "    e.add(Dense(256, activation='tanh', bias=True))\n",
    "    e.add(Dense(input_size, activation='tanh', bias=True))\n",
    "    e.compile(optimizer='adam', loss='mse')\n",
    "    return e\n",
    "\n",
    "e = encoder()\n",
    "\n",
    "d = decoder(e)\n",
    "\n",
    "d.fit(train_X, train_X, nb_epoch=nb_epochs, batch_size=batch_size)\n",
    "```\n",
    "\n",
    "output:\n",
    "```\n",
    "Epoch 26/30\n",
    "23617/23617 [==============================] - 7s 306us/step - loss: 0.1367\n",
    "Epoch 27/30\n",
    "23617/23617 [==============================] - 11s 472us/step - loss: 0.1357\n",
    "Epoch 28/30\n",
    "23617/23617 [==============================] - 8s 338us/step - loss: 0.1335\n",
    "Epoch 29/30\n",
    "23617/23617 [==============================] - 6s 264us/step - loss: 0.1334\n",
    "Epoch 30/30\n",
    "23617/23617 [==============================] - 11s 459us/step - loss: 0.1333\n",
    "\n",
    "<keras.callbacks.callbacks.History at 0x1e3918645c8>\n",
    "```\n",
    "\n",
    "```\n",
    "def classifier(d):\n",
    "    num_to_remove = 3\n",
    "    for i in range(num_to_remove):\n",
    "        d.pop()\n",
    "    d.add(Dense(128, input_dim=64, activation='tanh', bias=True))\n",
    "    d.add(Dense(128, activation='tanh', bias=True))\n",
    "    d.add(Dense(num_classes, activation='softmax', bias=True))\n",
    "    d.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return d\n",
    "\n",
    "c = classifier(d)\n",
    "\n",
    "c.fit(train_X, train_y, validation_data=(val_X, val_y), nb_epoch=nb_epochs, batch_size=batch_size)\n",
    "```\n",
    "\n",
    "output:\n",
    "```\n",
    "Epoch 26/30\n",
    "23617/23617 [==============================] - 16s 665us/step - loss: 2.1251 - accuracy: 0.1491 - val_loss: 2.1265 - val_accuracy: 0.1478\n",
    "Epoch 27/30\n",
    "23617/23617 [==============================] - 15s 623us/step - loss: 2.1243 - accuracy: 0.1480 - val_loss: 2.1234 - val_accuracy: 0.1477\n",
    "Epoch 28/30\n",
    "23617/23617 [==============================] - 16s 682us/step - loss: 2.1255 - accuracy: 0.1466 - val_loss: 2.1252 - val_accuracy: 0.1479\n",
    "Epoch 29/30\n",
    "23617/23617 [==============================] - 15s 651us/step - loss: 2.1246 - accuracy: 0.1463 - val_loss: 2.1204 - val_accuracy: 0.1456\n",
    "Epoch 30/30\n",
    "23617/23617 [==============================] - 8s 324us/step - loss: 2.1232 - accuracy: 0.1452 - val_loss: 2.1178 - val_accuracy: 0.1474\n",
    "```\n",
    "\n",
    "```\n",
    "loss, acc = c.evaluate(train_AP_features, train_labels)\n",
    "print(loss, acc)\n",
    "```\n",
    "output:\n",
    "```\n",
    "33938/33938 [==============================] - 2s 45us/step\n",
    "2.1182156826584446 0.1492132693529129\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
